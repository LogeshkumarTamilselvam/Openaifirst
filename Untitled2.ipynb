{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1LmIWibgSzzjP3FEtVoLrT0iePlFe190Z",
      "authorship_tag": "ABX9TyNXfbZZWMjIUj2B0OHrjgRK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LogeshkumarTamilselvam/Openaifirst/blob/main/Untitled2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Flgbzsb4ZuF9"
      },
      "outputs": [],
      "source": [
        "%%writefile LLM1.py\n",
        "import streamlit as st\n",
        "import openai\n",
        "import docx\n",
        "\n",
        "# Set your OpenAI API key The pipeline Initialize OpenAI API if using LLM approach\n",
        "openai.api_key = \"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\"\n",
        "\n",
        "#Ctreate a engine to define custom\n",
        "def localize_document(document, target_language):\n",
        "    # Perform localization using GPT-3.5 Turbo\n",
        "    prompt = f\"Localize the following document to {target_language}:\\n{document}\"\n",
        "    response = openai.Completion.create(\n",
        "        engine=\"text-davinci-003\",\n",
        "        prompt=prompt,\n",
        "        temperature=0.7,\n",
        "        max_tokens=1000\n",
        "    )\n",
        "    localized_document = response.choices[0].text.strip()\n",
        "    return localized_document\n",
        "\n",
        "#read and show the text from uploded file\n",
        "def read_docx(file_path):\n",
        "    doc = docx.Document(file_path)\n",
        "    content = [paragraph.text for paragraph in doc.paragraphs]\n",
        "    return \"\\n\".join(content)\n",
        "\n",
        "#define Streamlit app to use conver the language\n",
        "def main():\n",
        "    st.title(\"Demo Script Localizer\")\n",
        "#upload the demo script to engine\n",
        "    uploaded_file = st.file_uploader(\"Upload a DOCX file\", type=[\"docx\"])\n",
        "    if uploaded_file:\n",
        "        document = uploaded_file.read()\n",
        "\n",
        "        # Use the read_docx function to extract text content from DOCX\n",
        "        document_text = read_docx(uploaded_file)\n",
        "\n",
        "        st.text(\"Uploaded Document:\")\n",
        "        st.text(document_text)\n",
        "\n",
        "        target_language = st.text_input(\"Target Language:\", \"Spanish\")\n",
        "\n",
        "        if st.button(\"Localize\"):\n",
        "            localized_document = localize_document(document_text, target_language)\n",
        "            st.text(\"Localized Document:\")\n",
        "            st.text(localized_document)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Output - In this project, we will finally get Spanish output.\n",
        "\n",
        "A large language model is an advanced type of language model that is trained using deep learning techniques on massive amounts of text data. These models are capable of generating human-like text and performing various natural language processing tasks.\n",
        "\n",
        "The conclusion of the project, this project, i learn about more AL models and algorithms of how to run the AL models, This project more helps to develop my AL konwloge"
      ],
      "metadata": {
        "id": "brRmGUVJikRB"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "spIw6m-BWTUc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}